{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText\n",
    "<h4 style=\"font-size:14px; font-family:Calibry\" align=\"left\"> Andrii Kruchko </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "## Table of Contents\n",
    "\n",
    "<ol>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[FastText overview](#1)</li>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[Data preprocessing for fastText](#2)</li>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[Parameters overview and the model training](#3)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "## 1. FastText overview\n",
    "### What is it?\n",
    "\n",
    "FastText is a linear model with a rank constraint and a fast loss approximation.<br>\n",
    "It can obtain the accuracy comparable to deep learning classifiers.<br>\n",
    "\n",
    "But it is way faster:\n",
    "- FastText can train on more than one 200M words in less than five minutes using a standard multicore CPU\n",
    "- Classify nearly 150K reviews in less than a minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Architecture\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/akruchko/test/master/1_model_architecture_of_fastText.PNG\">\n",
    "The model architecture of fastText for a sentence with N ngram features x1, . . . , xN .<br> The features are embedded and averaged to form the hidden variable$^1$\n",
    "\n",
    "<hr style=\"height: 1px; width: 100px; background-color: #808080\"; align=\"left\"> <br>\n",
    "$^1$ https://arxiv.org/pdf/1607.01759.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "FastText uses the softmax function $f$ to compute the probability distribution over the predefined classes. For a set of N documents, this leads to minimizing the negative loglikelihood over the classes:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\ -\\frac{1}{N} \\sum_{n=1}^N y_n log(f(BAx_n))\n",
    "\\end{align}\n",
    "$x_n$ - the normalized bag of features of the n-th document, <br>\n",
    "$y_n$ - the label, <br>\n",
    "$A, B$ - weight matrices\n",
    "\n",
    "Optimization is performing using stochastic gradient descent and a linearly decaying learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "## 2. Data preprocessing for fastText\n",
    "- remove nonprintable characters\n",
    "- fix $n't$, $'re$, $'s$ and other cases\n",
    "- remove punctuation and digits\n",
    "- Porter stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from string import punctuation, digits\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fasttext import supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/movie_reviews.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare punctuation and digits list for removal\n",
    "translator = str.maketrans('', '', punctuation + digits)\n",
    "\n",
    "# basic preprocessing:\n",
    "def clean_data(df, col):\n",
    "    df['clean_text'] = df[col].str.replace('\\n', '').str.replace('\\r', '').str.replace('\\t', '')\n",
    "    df.clean_text = df.clean_text.str.replace(\"n't\", \" not\").str.replace(\"'re\", \" are\").str.replace(\"'s\", \" s\")\n",
    "    df.clean_text = df.clean_text.str.replace(\"'ve\", \" have\").str.replace(\"'ll\", \" will\").str.replace(\"'d\", \" d\")\n",
    "    df.clean_text = df.clean_text.str.translate(translator).str.strip().str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = clean_data(df_train, 'text')\n",
    "df_test = clean_data(df_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      " To an entire generation of filmgoers, it just might represent the most significant leap in storytelling that they will ever see...\n",
      "after:\n",
      " to an entire generation of filmgoers it just might represent the most significant leap in storytelling that they will ever see\n"
     ]
    }
   ],
   "source": [
    "print('before:\\n', df_train.text[0])\n",
    "print('after:\\n', df_train.clean_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Porter stemming\n",
    "stemmer = PorterStemmer()\n",
    "df_train['porter_text'] = df_train['clean_text'].apply(lambda x: ' '.join([stemmer.stem(w) for w in x.split()]))\n",
    "df_train = df_train[df_train.porter_text.apply(len) != 0]\n",
    "df_test['porter_text'] = df_test['clean_text'].apply(lambda x: ' '.join([stemmer.stem(w) for w in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before:\\n', df_train.clean_text[0])\n",
    "print('after:\\n', df_train.porter_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting on train and validation\n",
    "df_train2, df_val = train_test_split(df_train[['label', 'porter_text']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since fastText can be trained only from text files, we should mark labels. The default is `__label__` but can be custom.\n",
    "df_train2['ft_label'] = df_train2['label'].apply(lambda x: '__label__1 ' if x == 1 else '__label__0 ')\n",
    "df_train2[['ft_label', 'porter_text']].to_csv('../data/train_fastText.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and yet another preprocessing variant\n",
    "\n",
    "Weren't helpful:\n",
    "- default stop words make the model performance worse. The list should be revised or created from scratch\n",
    "- entities removal influences model's results badly. \n",
    "\n",
    "SpaCy lemmatization less aggressive than Porter stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "## 3. Parameters overview and the model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters overview\n",
    "\n",
    "- `lr` - learning rate. Default: **0.1**.\n",
    "- `dim` - size of word vectors in the hidden unit. Default: **100**. Should be less for small datasets and the number of labels.\n",
    "- `epoch` - number of epochs. Default: **5**. Higher for small learning rates.\n",
    "- `min_count` - minimal number of word occurences. Default: **1**. 5 or higher to avoid overfitting.\n",
    "- `word_ngrams` - max length of word ngram. Default: **1**. Higher order ngrams lead to overfitting on small datasets. if value greater than 1 learning rate and epoch should be revised.\n",
    "- `bucket` - number of buckets. Default: **2000000**. Developers recommend to use lower values for small datasets (ex. 100K).\n",
    "- `minn` - min length of char ngram. Default: **0**.\n",
    "- `maxn` - max length of char ngram. Default: **0**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(df, clf, label='label', text='porter_text', model_name='../data/fastText_porter'):\n",
    "  \n",
    "    prediction = clf.predict_proba(list(df[text]))\n",
    "    prediction = [int(item[0][0]) for item in prediction]\n",
    "\n",
    "    return [round(accuracy_score(list(df[label]), prediction), 4), \n",
    "            round(f1_score(list(df[label]), prediction, pos_label=0), 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare parameters for the grid search\n",
    "lrates = [0.5, 0.1, 0.01]\n",
    "epochs = [5, 10]\n",
    "min_c = [1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 48s, sys: 12.1 s, total: 7min\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# let's train models and evaluate them on the validation dataset\n",
    "# fastText requires at least two arguments a training file path and an output file path. In our case '../data/train_fastText.csv' and '../data/fastText_porter' respectively\n",
    "results = []\n",
    "for i in product(lrates, epochs, min_c):\n",
    "    clf = supervised('../data/train_fastText.csv', '../data/fastText_porter', label_prefix='__label__', \n",
    "                     lr=i[0], epoch=i[1], min_count=i[2])    \n",
    "    results.append(list(i) + get_score(df_val, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>epoch</th>\n",
       "      <th>min_count</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0.7733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8158</td>\n",
       "      <td>0.7722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.7713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0.7712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8158</td>\n",
       "      <td>0.7709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>0.7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8165</td>\n",
       "      <td>0.7699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.7682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>0.7659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.7633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7989</td>\n",
       "      <td>0.7426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.7378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lr  epoch  min_count  accuracy      f1\n",
       "0   0.50      5          5    0.8169  0.7733\n",
       "1   0.10     10          5    0.8158  0.7722\n",
       "2   0.50     10          5    0.8154  0.7713\n",
       "3   0.10      5          5    0.8169  0.7712\n",
       "4   0.10     10          1    0.8158  0.7709\n",
       "5   0.10      5          1    0.8166  0.7700\n",
       "6   0.50      5          1    0.8165  0.7699\n",
       "7   0.50     10          1    0.8160  0.7682\n",
       "8   0.01     10          5    0.8144  0.7659\n",
       "9   0.01     10          1    0.8137  0.7633\n",
       "10  0.01      5          5    0.7989  0.7426\n",
       "11  0.01      5          1    0.7972  0.7378"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results, columns=['lr', 'epoch', 'min_count', 'accuracy', 'f1']).sort_values(by='f1', ascending=False)\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's train the model with the best parameters\n",
    "clf = supervised('../data/train_fastText.csv', '../data/fastText_porter', label_prefix='__label__', \n",
    "                 lr=results.lr[0], epoch=results.epoch[0], min_count=results.min_count[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.7887 test f1: 0.7721\n"
     ]
    }
   ],
   "source": [
    "# and evaluate it in the test dataset\n",
    "acc, f1 = get_score(df_test, clf)\n",
    "print('test accuracy:', round(acc, 4), 'test f1:', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The exercise # 1\n",
    "Train models with predefined parameters and explain why such results were derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# A\n",
    "clf = supervised('../data/train_fastText.csv', '../data/fastText_porter', label_prefix='__label__', \n",
    "                 epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, f1 = get_score(df_val, clf)\n",
    "print('validation accuracy:', round(acc, 4), 'validation f1:', round(f1, 4))\n",
    "acc, f1 = get_score(df_test, clf)\n",
    "print('test accuracy:', round(acc, 4), 'test f1:', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click to see answer</summary>\n",
    "  <p align='left'>The high number of epochs leads to overfitting on the training dataset. It causes lower performances on the validation and the test dataset. </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# B\n",
    "clf = supervised('../data/train_fastText.csv', '../data/fastText_porter', label_prefix='__label__', \n",
    "                 word_ngrams=3, \n",
    "                 bucket=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, f1 = get_score(df_val, clf)\n",
    "print('validation accuracy:', round(acc, 4), 'validation f1:', round(f1, 4))\n",
    "acc, f1 = get_score(df_test, clf)\n",
    "print('test accuracy:', round(acc, 4), 'test f1:', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click to see answer</summary>\n",
    "  <p align='left'>Bag of n-grams much better represents reviews than bag of words. It leads to higher performances on the validation and the test dataset. </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The exercise # 2\n",
    "Try to improve the previous results using diiferent values of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = supervised('../data/train_fastText.csv', '../data/fastText_porter', label_prefix='__label__',\n",
    "                 lr=0.1, \n",
    "                 dim=100, \n",
    "                 epoch=5, \n",
    "                 min_count=1, \n",
    "                 word_ngrams=1, \n",
    "                 bucket=2000000, \n",
    "                 minn=0, \n",
    "                 maxn=0\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, f1 = get_score(df_val, clf)\n",
    "print('validation accuracy:', round(acc, 4), 'validation f1:', round(f1, 4))\n",
    "acc, f1 = get_score(df_test, clf)\n",
    "print('test accuracy:', round(acc, 4), 'test f1:', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click to see answer</summary>\n",
    "  <p align='left'>Based on previous examples we can try following parameters' values:</p>\n",
    "    <pre>\n",
    "      <code>\n",
    "     min_count=5, \n",
    "     word_ngrams=2, \n",
    "     bucket=2000000\n",
    "      </code>\n",
    "    </pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- Really fast: representing sentences with bag of words and bag of n-grams with hashing trick; a hierachical softmax\n",
    "- It was developed mainly for large datasets (ex. 1 billion words). In case of small datasets hyperparameters should be tuned carefully to avoid overfitting or you shoud get more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
