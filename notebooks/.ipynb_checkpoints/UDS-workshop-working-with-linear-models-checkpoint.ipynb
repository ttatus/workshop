{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--<h1 style=\"font-size:40px; font-family:Verdana\" align=\"center\"> UDS-Club Workshop </h1> -->\n",
    "<h2 style=\"font-size:34px; font-family:Verdana\" align=\"center\">Linear Models </h2>\n",
    "<!-- <img src='http://www.cmu.edu/africa/files/images/AppliedMachineLearningLogo.png'/> -->\n",
    "<img src='http://i.piccy.info/i9/666d78be04fbcf04fdb321d5953d1fa5/1492256847/123248/1137898/ua_parrots.jpg'/>\n",
    "<h4 style=\"font-size:18px; font-family:Verdana\" align=\"right\"> by Sergii Romanenk <br> <pre>    2017-04-23</pre> </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "<h2 style=\"font-size:25px; font-family:Verdana\" align=\"left\"> Table of Contents </h2>\n",
    "<ol>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[Naive Bayes](#1)</li>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[Passive Aggressive Classifier](#2)\n",
    "        <ul> \n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Introduction to online learning](#2_1)</li>\n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Three Decision Problems ](#2_2)</li>\n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[PassiveAgressive](#2_3)</li>\n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Three variants of the Passive-Aggressive algorithm](#2_4)</li> \n",
    "         </ul>\n",
    "    </li>\n",
    "    <li style=\"font-size:20px; font-family:Verdana\">[Practice](#3)\n",
    "        <ul> \n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Naive Bayes main params](#3_1)</li>\n",
    "            <li style=\"font-size:16px; font-family:Verdana\">[Passive-Aggressive main params](#3_2)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080\">\n",
    "## 1. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification is a fundamental issue in machine learning and data mining. In classification, the goal of a learning algorithm is to construct a classifier given a set of training examples with class labels. Typically, an example $E$ is represented by a tuple of attribute values ($x_1, x_2, … , x_n$), where $x_i$ is the value of attribute $X_i$. \n",
    "\n",
    "Let $C$ represent the classification variable, and let $c$ be the value of $C$. In this paper, we assume that there are only two classes: + (the positive class) or − (the negative class).\n",
    "\n",
    "A classifier is a function that assigns a class label to an example. From the probability perspective, according to Rule, the probability of an example $E = (x_1, x_2, … , x_n)$ being class $c$ is\n",
    "\n",
    "$$p(c|E) = {\\frac{p(E|c)p(c)}{p(E)}}$$\n",
    "\n",
    "$E$ is classified as the class $C = +$ if and only if\n",
    "$$f_b(E) = {\\frac{p(C = +|E)}{p(C = -|E)}}\\geq1$$\n",
    "\n",
    "\n",
    "where $f_b(E)$ is called a Bayesian classifier. Assume that all attributes are independent given the value of the class variable; that is,\n",
    "$$p(E|c) = p(x_1, x_2, … , x_n|c) = \\prod\\limits_{i = 1}^n p(x_i|c)$$\n",
    "the resulting classifier is then:\n",
    "$$f_{nb}(E) = {\\frac{p(C = +)}{p(C = -)}} \\prod\\limits_{i = 1}^n {\\frac{p(x_i|c = +)}{p(x_i|c = -)}} $$\n",
    "The function $f_{nb}(E)$ is called a naive Bayesian classifier, or simply naive Bayes (NB). Figure 1 shows an example of naive Bayes. In naive Bayes, each attribute node has no parent except the class node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://i.piccy.info/i9/e3f799752a613ded34b7d17feaf2eca4/1492605985/18456/1138938/NB5.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is the simplest form of Bayesian network, in which all attributes are independent given the value of the class variable. This is called conditional independence. It is obvious that the conditional independence assumption is rarely true in most real-world applications. A straightforward approach to overcome the limitation of naive Bayes is to extend its structure to represent explicitly the dependencies among attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080 border: dashed 1px\">\n",
    "## 2. Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "### 2.1 Introduction to online learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Online Learning is generally described as doing machine learning in a streaming data setting, i.e. training a model in consecutive rounds. After each observation, the algorithm predicts an outcome.\n",
    "<ul>\n",
    "    <li> Once the algorithm has made a prediction, it receives feedback indicating the correct outcome </li>\n",
    "    <li> Then, the online algorithm may modify its prediction mechanism, presumably improving the chances of making an accurate prediction on subsequent rounds </li>    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.doyensahoo.com/uploads/5/3/7/3/53734297/6829966.jpg?758' width ='70%' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li> For PA we use instantaneous loss which reflects the degree to which its prediction was wrong. This loss is defined by the following hinge-loss function: </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://i.piccy.info/i9/f49ca2db5a056f99baf387e03ed66cd0/1492606078/18244/1138938/hinge_loss.jpg' width ='90%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Online algorithms are useful in an least two scenarios:\n",
    "<ul>\n",
    "<li> When your data is too large to fit in the memory </li>\n",
    "<li type=\"circle\" style=\"margin-left: 40px;\"> So you need to train your model one example at a time </li>\n",
    "<li> When new data is constantly being generated and/or is dependent upon time </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Implementations:\n",
    "<ul>\n",
    "<li> Vowpal Wabbit: Open-source fast out-of-core online learning system which is notable for supporting a number of machine learning reductions, importance weighting and a selection of different loss functions and optimisation algorithms. It uses the hashing trick for bounding the size of the set of features independent of the amount of training data. </li>\n",
    "<li> scikit-learn: Provides out-of-core implementations of algorithms for </li>\n",
    "<li type=\"circle\" style=\"margin-left: 40px;\"> Classification: Perceptron, SGD classifier, Naive bayes classifier. </li>\n",
    "<li type=\"circle\" style=\"margin-left: 40px;\"> Regression: SGD Regressor, Passive Aggressive regressor.</li>\n",
    "\n",
    "<li type=\"circle\" style=\"margin-left: 40px;\"> Clustering: Mini-batch k-means. </li>\n",
    "<li type=\"circle\" style=\"margin-left: 40px;\"> Feature extraction: Mini-batch dictionary learning, Incremental PCA.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "### 2.2  Three Decision Problems \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'http://i.piccy.info/i9/e32c66ef69d07817b1d4265be4cd98e5/1492606133/33144/1138938/3decision_problems.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will look only on classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "### 2.3 PassiveAgressive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'http://i.piccy.info/i9/5c95a32f9c206cb128eea3da331be485/1492606155/47062/1138938/PAC.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'http://i.piccy.info/i9/f1d43b05b66a635e0624de737034298a/1492606196/17941/1138938/PA.jpg' width ='90%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting algorithm is <i>passive</i> whenever the <i>hinge-loss</i> is zero, that is, $w_{t+1} = w_t$ whenever $ℓ_t = 0$. \n",
    "In contrast, on those rounds where the loss is positive, the algorithm <i>aggressively</i> forces wt+1 to satisfy the constraint $ℓ(w_{t+1}; (x_t , y_t)) = 0 $ regardless of the step-size required. \n",
    "We therefore name the algorithm <i>Passive-Aggressive</i> or PA for short.\n",
    "\n",
    "The solution to the optimization problem in Eq. (2) has a simple closed form solution,\n",
    "$$w_{t+1} = w_t + \\tau_ty_tx_t \\text{ where } \\tau_t = {\\frac{l_t}{\\|x_t\\|^2}} \\text{ (3)}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2_4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "\n",
    "### 2.4 Three variants of the Passive-Aggressive algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'http://i.piccy.info/i9/f000a4098f2e54a44dbea9b9381e2129/1492606243/19526/1138938/PAs.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C -- aggressiveness parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 1px; background-color: #808080 border: dashed 1px\">\n",
    "## 3. Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data for train  \n",
    "train = pd.read_csv('../data/movie_reviews.csv', sep = ',')\n",
    "train_data = train.text\n",
    "train_labels = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data for test \n",
    "test = pd.read_csv('../data/test.csv', sep = ',')\n",
    "test_data = test.text\n",
    "test_labels = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "train_data, train_validation_data, train_labels, train_validation_labels = train_test_split(train.text, train.label, test_size=0.2, random_state=42, stratify=train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the last 22 words from each review in the train set\n",
    "train_data = train_data.str.split().apply(lambda x:  ' '.join(x for x in x[-22:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of stopwords\n",
    "STOPWORDS = ['by','does', 'was', 'were', 'the', 'of', 'end', 'and', 'is']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert text to vector\n",
    "cvect = CountVectorizer()\n",
    "counts = cvect.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "\n",
    "### 3.1 Naive Bayes main params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train NB\n",
    "classifier = MultinomialNB(alpha=0.4)\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(binary=True,ngram_range=(1,3),stop_words=STOPWORDS)), ('classifier', classifier)])\n",
    "model = pipeline.fit(X=train_data, y=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.818589869602\n",
      "F1-score : 0.848388598341\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "pred_test = model.predict(train_validation_data)\n",
    "\n",
    "print (\"Accuracy :\", metrics.accuracy_score(train_validation_labels, pred_test))\n",
    "print (\"F1-score :\", metrics.f1_score(train_validation_labels, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8095684803\n",
      "F1-score : 0.825180847399\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "pred_test = model.predict(test_data)\n",
    "\n",
    "print (\"Accuracy :\", metrics.accuracy_score(test_labels, pred_test))\n",
    "print (\"F1-score :\", metrics.f1_score(test_labels, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dashed #ffffff;\" />\n",
    "\n",
    "### 3.2 Passive-Aggressive main params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>C</b> : float\n",
    "Maximum step size (regularization). Defaults to 1.0.\n",
    "\n",
    "<b>fit_intercept</b> : bool, default=False\n",
    "Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.\n",
    "\n",
    "<b>n_iter</b> : int, optional\n",
    "The number of passes over the training data (aka epochs). Defaults to 5.\n",
    "\n",
    "<b>shuffle</b> : bool, default=True\n",
    "Whether or not the training data should be shuffled after each epoch.\n",
    "\n",
    "<b>random_state</b> : int seed, RandomState instance, or None (default)\n",
    "The seed of the pseudo random number generator to use when shuffling the data.\n",
    "\n",
    "<b>verbose </b>: integer, optional\n",
    "The verbosity level\n",
    "\n",
    "<b>n_jobs</b> : integer, optional\n",
    "The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. -1 means ‘all CPUs’. Defaults to 1.\n",
    "\n",
    "<b>loss</b> : string, optional\n",
    "The loss function to be used: hinge: equivalent to PA-I in the reference paper. squared_hinge: equivalent to PA-II in the reference paper.\n",
    "\n",
    "<b>warm_start</b> : bool, optional\n",
    "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution.\n",
    "\n",
    "<b>class_weight</b> : dict, {class_label: weight} or “balanced” or None, optional\n",
    "Preset for the class_weight fit parameter.\n",
    "Weights associated with classes. If not given, all classes are supposed to have weight one.\n",
    "The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PA\n",
    "classifier = PassiveAggressiveClassifier(C=0.001, fit_intercept = True, shuffle = False, loss = 'squared_hinge', n_iter = 91, n_jobs = -1, class_weight='balanced')\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(binary=True,ngram_range=(1,4),stop_words=STOPWORDS)), ('classifier', classifier)])\n",
    "model = pipeline.fit(X=train_data, y=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.841491383265\n",
      "F1-score : 0.868008948546\n"
     ]
    }
   ],
   "source": [
    "# Validation \n",
    "pred_test = model.predict(train_validation_data)\n",
    "\n",
    "print (\"Accuracy :\", metrics.accuracy_score(train_validation_labels, pred_test))\n",
    "print (\"F1-score :\", metrics.f1_score(train_validation_labels, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.830300187617\n",
      "F1-score : 0.841496539034\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "pred_test = model.predict(test_data)\n",
    "\n",
    "print (\"Accuracy :\", metrics.accuracy_score(test_labels, pred_test))\n",
    "print (\"F1-score :\", metrics.f1_score(test_labels, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-size:16px; font-family:Verdana\">[To the table of contents](#0)</h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
